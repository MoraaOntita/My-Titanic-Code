{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-19T18:15:47.986667Z","iopub.execute_input":"2023-11-19T18:15:47.987029Z","iopub.status.idle":"2023-11-19T18:15:50.297911Z","shell.execute_reply.started":"2023-11-19T18:15:47.987000Z","shell.execute_reply":"2023-11-19T18:15:50.296554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntrain['train_test'] = 1\ntest['train_test'] = 0\ntest['Survived'] = np.NaN\ndata = pd.concat([train,test])\n\n%matplotlib inline\ndata.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:15:50.299631Z","iopub.execute_input":"2023-11-19T18:15:50.300151Z","iopub.status.idle":"2023-11-19T18:15:50.362277Z","shell.execute_reply.started":"2023-11-19T18:15:50.300121Z","shell.execute_reply":"2023-11-19T18:15:50.361134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_num = train[[\"Age\",\"SibSp\", \"Parch\", \"Fare\"]]\ndf_cat = train[[\"Survived\", \"Pclass\", \"Sex\", \"Cabin\", \"Embarked\",\"Ticket\"]]","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:15:50.363559Z","iopub.execute_input":"2023-11-19T18:15:50.363891Z","iopub.status.idle":"2023-11-19T18:15:50.371210Z","shell.execute_reply.started":"2023-11-19T18:15:50.363862Z","shell.execute_reply":"2023-11-19T18:15:50.370352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in df_num.columns:\n    plt.figure(figsize=(8, 6))  # Set the figure size for each histogram\n    plt.hist(df_num[column]) \n    plt.xlabel(column)  # Set the x-axis label to the column name\n    plt.ylabel('Frequency')\n    plt.title(f'Histogram of {column}')\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:15:50.373164Z","iopub.execute_input":"2023-11-19T18:15:50.373656Z","iopub.status.idle":"2023-11-19T18:15:51.549008Z","shell.execute_reply.started":"2023-11-19T18:15:50.373627Z","shell.execute_reply":"2023-11-19T18:15:51.547957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_num.corr())\nprint(df_num.corr())","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:15:51.550166Z","iopub.execute_input":"2023-11-19T18:15:51.550507Z","iopub.status.idle":"2023-11-19T18:15:51.893544Z","shell.execute_reply.started":"2023-11-19T18:15:51.550458Z","shell.execute_reply":"2023-11-19T18:15:51.892527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_table = train.pivot_table(\n   index = \"Survived\",\n    values = [\"Age\", \"SibSp\", \"Fare\", \"Parch\"]\n    )\npivot_table\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:15:51.895086Z","iopub.execute_input":"2023-11-19T18:15:51.895721Z","iopub.status.idle":"2023-11-19T18:15:51.924537Z","shell.execute_reply.started":"2023-11-19T18:15:51.895691Z","shell.execute_reply":"2023-11-19T18:15:51.923505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in df_cat.columns:\n    sns.barplot(\n        x = df_cat[column].value_counts().index,\n        y = df_cat[column].value_counts()\n    ).set_title(column)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:15:51.926227Z","iopub.execute_input":"2023-11-19T18:15:51.926711Z","iopub.status.idle":"2023-11-19T18:16:00.281713Z","shell.execute_reply.started":"2023-11-19T18:15:51.926671Z","shell.execute_reply":"2023-11-19T18:16:00.280583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pd.pivot_table(train, index = \"Survived\", columns = \"Sex\", \n                     values = \"Ticket\", aggfunc = \"count\"))\n\nprint(pd.pivot_table(train, index = \"Survived\", columns = \"Pclass\", \n                     values = \"Ticket\", aggfunc = \"count\"))\n\nprint(pd.pivot_table(train, index = \"Survived\", columns = \"Embarked\", \n                     values = \"Ticket\", aggfunc = \"count\"))\n\nprint(pd.pivot_table(train, index = \"Survived\", columns = \"Cabin\", \n                     values = \"Ticket\", aggfunc = \"count\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.283310Z","iopub.execute_input":"2023-11-19T18:16:00.284390Z","iopub.status.idle":"2023-11-19T18:16:00.337847Z","shell.execute_reply.started":"2023-11-19T18:16:00.284354Z","shell.execute_reply":"2023-11-19T18:16:00.336689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Cabin\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.341222Z","iopub.execute_input":"2023-11-19T18:16:00.341602Z","iopub.status.idle":"2023-11-19T18:16:00.350912Z","shell.execute_reply.started":"2023-11-19T18:16:00.341573Z","shell.execute_reply":"2023-11-19T18:16:00.349828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Multiple_cabins\"] = train.Cabin.apply(lambda column: 0 if pd.isna(column) \n                                             else len(column.split(\" \")))\ntrain[\"Multiple_cabins\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.355106Z","iopub.execute_input":"2023-11-19T18:16:00.355542Z","iopub.status.idle":"2023-11-19T18:16:00.370517Z","shell.execute_reply.started":"2023-11-19T18:16:00.355501Z","shell.execute_reply":"2023-11-19T18:16:00.369208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define a function to calculate the number of cabins\ndef number_of_cabins(column):\n    if pd.isna(column):\n        return 0\n    else:\n        return len(column.split(\" \"))\n        \ntrain[\"multiple_cabin\"] = train[\"Cabin\"].apply(number_of_cabins)\ntrain[\"multiple_cabin\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.371845Z","iopub.execute_input":"2023-11-19T18:16:00.372677Z","iopub.status.idle":"2023-11-19T18:16:00.385117Z","shell.execute_reply.started":"2023-11-19T18:16:00.372638Z","shell.execute_reply":"2023-11-19T18:16:00.383994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(train, index=\"Survived\", columns = \"Multiple_cabins\",\n               values = \"Ticket\", aggfunc = \"count\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.386601Z","iopub.execute_input":"2023-11-19T18:16:00.386949Z","iopub.status.idle":"2023-11-19T18:16:00.411330Z","shell.execute_reply.started":"2023-11-19T18:16:00.386916Z","shell.execute_reply":"2023-11-19T18:16:00.410526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check the letters of the cabins \ntrain[\"Cabin_letters\"] = train.Cabin.apply(lambda column: str(column)[0])\ntrain[\"Cabin_letters\"]","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.412595Z","iopub.execute_input":"2023-11-19T18:16:00.412897Z","iopub.status.idle":"2023-11-19T18:16:00.424396Z","shell.execute_reply.started":"2023-11-19T18:16:00.412872Z","shell.execute_reply":"2023-11-19T18:16:00.423342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(train, index = \"Survived\", columns = \"Cabin_letters\",\n               values = \"Name\", aggfunc = \"count\")\ntrain[\"Cabin_letters\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.426339Z","iopub.execute_input":"2023-11-19T18:16:00.426818Z","iopub.status.idle":"2023-11-19T18:16:00.447155Z","shell.execute_reply.started":"2023-11-19T18:16:00.426780Z","shell.execute_reply":"2023-11-19T18:16:00.445987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_table_2 = train.pivot_table(index = \"Survived\", columns = \"Cabin_letters\", \n                                  values = \"Name\", aggfunc = \"count\" )\npivot_table_2","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.448798Z","iopub.execute_input":"2023-11-19T18:16:00.449224Z","iopub.status.idle":"2023-11-19T18:16:00.475411Z","shell.execute_reply.started":"2023-11-19T18:16:00.449187Z","shell.execute_reply":"2023-11-19T18:16:00.474265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"ticket_numerics\"] = train.Ticket.apply(lambda column: 1 if column.isnumeric() else 0 )\ntrain[\"ticket_letters\"] = train.Ticket.apply(lambda column: ' '.join(column.split(' ')[:-1])\n                                             .replace('.', '').replace('/', '').lower()\n                                            if len(column.split(' ')[:-1]) >0 else 0)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.476633Z","iopub.execute_input":"2023-11-19T18:16:00.476952Z","iopub.status.idle":"2023-11-19T18:16:00.486098Z","shell.execute_reply.started":"2023-11-19T18:16:00.476926Z","shell.execute_reply":"2023-11-19T18:16:00.484744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_rows\", None)\ntrain[\"ticket_letters\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.488039Z","iopub.execute_input":"2023-11-19T18:16:00.488442Z","iopub.status.idle":"2023-11-19T18:16:00.505234Z","shell.execute_reply.started":"2023-11-19T18:16:00.488403Z","shell.execute_reply":"2023-11-19T18:16:00.503867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.pivot_table(index = \"Survived\", columns=\"ticket_numerics\", values=\"Ticket\", aggfunc = \"count\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.506846Z","iopub.execute_input":"2023-11-19T18:16:00.507349Z","iopub.status.idle":"2023-11-19T18:16:00.527274Z","shell.execute_reply.started":"2023-11-19T18:16:00.507309Z","shell.execute_reply":"2023-11-19T18:16:00.526221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.pivot_table(index=\"Survived\", columns = \"ticket_letters\", values = \"Ticket\", aggfunc=\"count\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.528445Z","iopub.execute_input":"2023-11-19T18:16:00.528791Z","iopub.status.idle":"2023-11-19T18:16:00.566506Z","shell.execute_reply.started":"2023-11-19T18:16:00.528764Z","shell.execute_reply":"2023-11-19T18:16:00.565666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Name\"].head(10)\ntrain[\"name_title\"] = train.Name.apply(lambda column: column.split(\",\")[1].split(\".\")[0].strip())\ntrain[\"name_title\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.567355Z","iopub.execute_input":"2023-11-19T18:16:00.567675Z","iopub.status.idle":"2023-11-19T18:16:00.580243Z","shell.execute_reply.started":"2023-11-19T18:16:00.567648Z","shell.execute_reply":"2023-11-19T18:16:00.578958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create the categorical variables\ndata[\"Multiple_cabins\"] = data.Cabin.apply(lambda column: 0 if pd.isna(column) \n                                             else len(column.split(\" \")))\ndata[\"Cabin_letters\"] = data.Cabin.apply(lambda column: str(column)[0])\ndata[\"ticket_numerics\"] = data.Ticket.apply(lambda column: 1 if column.isnumeric() else 0 )\ndata[\"ticket_letters\"] = data.Ticket.apply(lambda column: ' '.join(column.split(' ')[:-1])\n                                             .replace('.', '').replace('/', '').lower()\n                                            if len(column.split(' ')[:-1]) >0 else 0)\ndata[\"name_title\"] = data.Name.apply(lambda column: column.split(\",\")[1].split(\".\")[0].strip())\n\n\n#drop the null values in the embarked column\ndata.dropna(subset = [\"Embarked\"], inplace=True)\n\n#include the relevant data\ndata[\"Age\"] = data[\"Age\"].fillna(data.Age.mean())\ndata[\"Fare\"] = data[\"Fare\"].fillna(data.Fare.median())\n\n#transform the categorical data\ndata[\"norm_sibsp\"] = np.log(data.SibSp+1)\ndata[\"norm_sibsp\"].hist()\n#impute the fare ad the age data\ndata[\"norm_fare\"] = np.log(data.Fare+1)\ndata[\"norm_fare\"].hist()\n\n#converting pclass to a str from a int\ndata[\"Pclass\"].astype(str)\n#getting the dummies\ndata_dummies = pd.get_dummies(data[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"norm_fare\", \n                \"Embarked\", \"Cabin_letters\", \"Multiple_cabins\", \"ticket_numerics\",\n                \"name_title\", \"train_test\"]])\n\n#splittig the data ito train and test sets\nX_train = data_dummies[data_dummies.train_test == 1].drop(['train_test'], axis =1)\nX_test = data_dummies[data_dummies.train_test == 0].drop(['train_test'], axis =1)\n\n\ny_train = data[data.train_test==1].Survived\ny_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.582441Z","iopub.execute_input":"2023-11-19T18:16:00.582936Z","iopub.status.idle":"2023-11-19T18:16:00.924712Z","shell.execute_reply.started":"2023-11-19T18:16:00.582895Z","shell.execute_reply":"2023-11-19T18:16:00.923564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscale = StandardScaler()\n\ndata_dummies_scaled = data_dummies.copy()\ndata_dummies_scaled[[\"Age\", \"SibSp\", \"Parch\", \"norm_fare\"]] = scale.fit_transform(\n    data_dummies_scaled[[\"Age\", \"SibSp\", \"Parch\", \"norm_fare\"]])\n\nX_trained_scaled = data_dummies_scaled[\n    data_dummies_scaled.train_test == 1].drop(['train_test'], axis =1)\n\nX_test_scaled = data_dummies_scaled[\n    data_dummies_scaled.train_test == 0].drop(['train_test'], axis =1)\n\ny_train = data[data.train_test==1].Survived\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.926161Z","iopub.execute_input":"2023-11-19T18:16:00.927304Z","iopub.status.idle":"2023-11-19T18:16:00.946458Z","shell.execute_reply.started":"2023-11-19T18:16:00.927257Z","shell.execute_reply":"2023-11-19T18:16:00.944963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\n\n#list of Models\nmodels = [\n    #LinearRegression(),\n    LogisticRegression(max_iter = 2000),\n    DecisionTreeClassifier(random_state = 42),\n    RandomForestClassifier(random_state = 42),\n    GradientBoostingClassifier(n_estimators=100, random_state =42),\n    SVC(probability = True),\n    KNeighborsClassifier(),\n    GaussianNB(),\n]\n\nfor model in models:\n    scores = cross_val_score(model, X_train, y_train, cv = 5, scoring=\"accuracy\")\n    scores_1 = cross_val_score(model, X_trained_scaled, y_train, cv = 5, scoring=\"accuracy\")\n    print(f\"Model: {model.__class__.__name__}\")\n    print(\"Cross-Validation Scores:\", scores)\n    print(\"Mean Accuracy:\", np.mean(scores))\n    print(\"Mean Accuracy:\", np.mean(scores_1))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:00.948412Z","iopub.execute_input":"2023-11-19T18:16:00.948902Z","iopub.status.idle":"2023-11-19T18:16:07.955966Z","shell.execute_reply.started":"2023-11-19T18:16:00.948857Z","shell.execute_reply":"2023-11-19T18:16:07.954917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\n#Create an instance of all the models\nlog = LogisticRegression(max_iter = 2000) \nD_trees = DecisionTreeClassifier(random_state = 42)\nr_forest = RandomForestClassifier(random_state = 42)\ng_boost = GradientBoostingClassifier(random_state =42)\nknn = KNeighborsClassifier()\nnaive_bayes = GaussianNB() \n\nv_clf = VotingClassifier(estimators = [\n    (\"log\", log),\n    (\"D_trees\",D_trees),\n    (\"r_forest\", r_forest),\n    (\"g_boost\", g_boost),\n    (\"knn\", knn),\n    (\"naives_bayes\", naive_bayes)\n], voting=\"soft\")\n\nscores = cross_val_score(v_clf, X_train, y_train, cv=5)\nprint(scores)\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:07.957269Z","iopub.execute_input":"2023-11-19T18:16:07.957606Z","iopub.status.idle":"2023-11-19T18:16:11.713234Z","shell.execute_reply.started":"2023-11-19T18:16:07.957578Z","shell.execute_reply":"2023-11-19T18:16:11.712347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v_clf.fit(X_trained_scaled,y_train)\ny_hat_base_vc = v_clf.predict(X_test_scaled).astype(int)\nbasic_submission = {'PassengerId': test.PassengerId, 'Survived': y_hat_base_vc}\nbase_submission = pd.DataFrame(data=basic_submission)\nbase_submission.to_csv('base_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:11.714385Z","iopub.execute_input":"2023-11-19T18:16:11.714853Z","iopub.status.idle":"2023-11-19T18:16:12.494341Z","shell.execute_reply.started":"2023-11-19T18:16:11.714825Z","shell.execute_reply":"2023-11-19T18:16:12.493361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\n#defining the hyperparameters for all the possible models\nparams_grids = {\n    \"logistic_regression\" : {'max_iter' : [2000],\n                      'penalty' : ['l1', 'l2'],\n                      'C' : np.logspace(-4, 4, 20),\n                      'solver' : ['liblinear']},\n    \n    \"knn\": { 'n_neighbors' : [3,5,7,9],\n              'weights' : ['uniform', 'distance'],\n              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n              'p' : [1,2]},\n    \n    \"random_forest\": {'n_estimators': [100,500,1000], \n                                  'bootstrap': [True,False],\n                                  'max_depth': [3,5,10,20,50,75,100,None],\n                                  'min_samples_leaf': [1,2,4,10],\n                                  'min_samples_split': [2,5,10]},\n    \n    \"gradient_boosting\": {'n_estimators': [50, 100, 200], 'max_depth': [15, 20, 25]},\n}\n\n# Models to be used in grid search and randomized search\nmodels = {\n    'logistic_regression': LogisticRegression(),\n    'random_forest': RandomForestClassifier(),\n    'gradient_boosting': GradientBoostingClassifier(),\n    'knn': KNeighborsClassifier(),\n    \n}\n\n\n#performing randomized and grid search  for every model\nfor model_name, model in models.items():\n    print(f\"Performing Grid Search for {model_name}...\")\n    grid_search = GridSearchCV(estimator = model, param_grid = params_grids[model_name], \n                              cv = 5, verbose = True, n_jobs = -1,\n                               scoring = \"accuracy\").fit(X_trained_scaled, y_train)\n    best_params_grid = grid_search.best_params_\n    best_score_grid = grid_search.best_score_\n    best_estimator_grid = grid_search.best_estimator_\n    \n    print(f\"Hyperparameters (Grid Search) for {model_name}: {best_params_grid}\")\n    print(f\"Best Score (Grid Search)  for {model_name}: {best_score_grid}\\n\")\n    print(f\"Best Estimator (Grid Search) for {model_name}: {best_estimator_grid}\\n\")\n    \n    \n    print(f\"Performing Randomized Search for {model_name}...\")\n    param_dist = params_grids[model_name]\n    randomized_search = RandomizedSearchCV(estimator = model, param_distributions=param_dist, \n                                           n_iter = 100, cv = 5, verbose = True, \n                                           n_jobs = -1).fit(X_trained_scaled, y_train)\n    \n    best_params_randomized = randomized_search.best_params_\n    best_score_randomized =  randomized_search.best_score_\n    print(f\"Best Hyperparameters (Randomized Search) for {model_name}: {best_params_randomized}\")\n    print(f\"Best Score (Randomized Search) for {model_name}: {best_score_randomized}\\n\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:16:12.495717Z","iopub.execute_input":"2023-11-19T18:16:12.496042Z","iopub.status.idle":"2023-11-19T18:38:24.707753Z","shell.execute_reply.started":"2023-11-19T18:16:12.496014Z","shell.execute_reply":"2023-11-19T18:38:24.706889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#simple performance reporting function\ndef clf_performance(classifier, model_name):\n    print(model_name)\n    print('Best Score: ' + str(classifier.best_score_))\n    print('Best Parameters: ' + str(classifier.best_params_))","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:38:24.709327Z","iopub.execute_input":"2023-11-19T18:38:24.709887Z","iopub.status.idle":"2023-11-19T18:38:24.714166Z","shell.execute_reply.started":"2023-11-19T18:38:24.709849Z","shell.execute_reply":"2023-11-19T18:38:24.713384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression()\nparam_grid = {'max_iter' : [2000],\n              'penalty' : ['l1', 'l2'],\n              'C' : np.logspace(-4, 4, 20),\n              'solver' : ['liblinear']}\n\nclf_lr = GridSearchCV(lr, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_lr = clf_lr.fit(X_trained_scaled,y_train)\nclf_performance(best_clf_lr,'Logistic Regression')","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:38:24.719731Z","iopub.execute_input":"2023-11-19T18:38:24.720052Z","iopub.status.idle":"2023-11-19T18:38:26.689251Z","shell.execute_reply.started":"2023-11-19T18:38:24.720025Z","shell.execute_reply":"2023-11-19T18:38:26.688016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier()\nparam_grid = {'n_neighbors' : [3,5,7,9],\n              'weights' : ['uniform', 'distance'],\n              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n              'p' : [1,2]}\nclf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_knn = clf_knn.fit(X_trained_scaled,y_train)\nclf_performance(best_clf_knn,'KNN')","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:38:26.690941Z","iopub.execute_input":"2023-11-19T18:38:26.691384Z","iopub.status.idle":"2023-11-19T18:38:28.540115Z","shell.execute_reply.started":"2023-11-19T18:38:26.691346Z","shell.execute_reply":"2023-11-19T18:38:28.538975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(random_state = 1)\nparam_grid =  {'n_estimators': [400,450,500,550],\n               'criterion':['gini','entropy'],\n                                  'bootstrap': [True],\n                                  'max_depth': [15, 20, 25],\n                                  'min_samples_leaf': [2,3],\n                                  'min_samples_split': [2,3]}\n                                  \nclf_rf = GridSearchCV(rf, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_rf = clf_rf.fit(X_trained_scaled,y_train)\nclf_performance(best_clf_rf,'Random Forest')","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:38:28.548848Z","iopub.execute_input":"2023-11-19T18:38:28.549828Z","iopub.status.idle":"2023-11-19T18:41:33.119116Z","shell.execute_reply.started":"2023-11-19T18:38:28.549797Z","shell.execute_reply":"2023-11-19T18:41:33.117988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_rf = best_clf_rf.best_estimator_.fit(X_trained_scaled,y_train)\nfeat_importances = pd.Series(best_rf.feature_importances_, index=X_trained_scaled.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:41:33.120515Z","iopub.execute_input":"2023-11-19T18:41:33.120848Z","iopub.status.idle":"2023-11-19T18:41:34.651420Z","shell.execute_reply.started":"2023-11-19T18:41:33.120819Z","shell.execute_reply":"2023-11-19T18:41:34.650220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimators = {}\n\nfor model_name, model in models.items():\n    best_estimators[f\"{model_name}_GridSearch\"] = grid_search.best_estimator_\n    best_estimators[f'{model_name}_RandomizedSearch'] = randomized_search.best_estimator_\n    \n    print(f\"Best Estimator{best_estimators}\")\n#doing now the voting  classifier hard and soft\nvoting_clf_hard = VotingClassifier(\n    estimators=[(model_name, estimator) for model_name, estimator in best_estimators.items()],\n    voting=\"hard\"\n)\nvoting_clf_soft = VotingClassifier(\n    estimators=[(model_name, estimator) for model_name, estimator in best_estimators.items()],\n    voting= \"soft\"\n)\n\nprint('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\nprint('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n\nprint('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\nprint('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:41:34.652975Z","iopub.execute_input":"2023-11-19T18:41:34.653393Z","iopub.status.idle":"2023-11-19T18:41:37.363127Z","shell.execute_reply.started":"2023-11-19T18:41:34.653356Z","shell.execute_reply":"2023-11-19T18:41:37.361155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_lr = best_clf_lr.best_estimator_\nbest_knn = best_clf_knn.best_estimator_\nbest_rf = best_clf_rf.best_estimator_\n\n\nvoting_clf_hard = VotingClassifier(estimators = [\n    ('knn',best_knn),('rf',best_rf)], voting = \"hard\")  \nvoting_clf_soft = VotingClassifier(estimators = [\n    ('knn',best_knn),('rf',best_rf)], voting = \"soft\") \nvoting_clf_all = VotingClassifier(estimators = [\n    ('knn',best_knn),('rf',best_rf), ('lr', best_lr)], voting = 'soft') \n\nprint('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\nprint('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n\nprint('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\nprint('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())\n\nprint('voting_clf_all :',cross_val_score(voting_clf_all,X_train,y_train,cv=5))\nprint('voting_clf_all mean :',cross_val_score(voting_clf_all,X_train,y_train,cv=5).mean())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:41:37.364613Z","iopub.execute_input":"2023-11-19T18:41:37.365053Z","iopub.status.idle":"2023-11-19T18:42:10.988457Z","shell.execute_reply.started":"2023-11-19T18:41:37.365012Z","shell.execute_reply":"2023-11-19T18:42:10.986529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Doing the weighting to asses the quality of our data and if our weighting is correct\n\nparams = {'weights' : [[1,1],[1,2],[2,1]]}\n\nvote_weight = GridSearchCV(voting_clf_soft, param_grid = params, cv = 5, verbose = True, n_jobs = -1)\nbest_clf_weight = vote_weight.fit(X_trained_scaled,y_train)\nclf_performance(best_clf_weight,'VC Weights')\nvoting_clf_sub = best_clf_weight.best_estimator_.predict(X_test_scaled)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T18:42:10.989569Z","iopub.execute_input":"2023-11-19T18:42:10.989860Z","iopub.status.idle":"2023-11-19T18:42:18.949097Z","shell.execute_reply.started":"2023-11-19T18:42:10.989835Z","shell.execute_reply":"2023-11-19T18:42:18.947899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fittig the data \nvoting_clf_hard.fit(X_trained_scaled, y_train)\nvoting_clf_soft.fit(X_trained_scaled, y_train)\nvoting_clf_all.fit(X_trained_scaled, y_train)\nbest_rf.fit(X_trained_scaled, y_train)\n\n#Make Predictions\ny_vc_hard = voting_clf_hard.predict(X_test_scaled).astype(int)\ny_rf = best_rf.predict(X_test_scaled).astype(int)\ny_soft =  voting_clf_soft.predict(X_test_scaled).astype(int)\ny_vc_all = voting_clf_all.predict(X_test_scaled).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:35:35.414506Z","iopub.execute_input":"2023-11-19T19:35:35.414927Z","iopub.status.idle":"2023-11-19T19:35:40.288511Z","shell.execute_reply.started":"2023-11-19T19:35:35.414894Z","shell.execute_reply":"2023-11-19T19:35:40.287230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_1 = {'PassengerId': test.PassengerId, 'Survived': y_rf}\nsubmission = pd.DataFrame(data = output_1)\n\noutput_2 = {'PassengerId': test.PassengerId, 'Survived': y_vc_hard}\nsubmission_1 = pd.DataFrame(data = output_2)\n\noutput_3 = {'PassengerId': test.PassengerId, 'Survived': y_soft}\nsubmission_2 = pd.DataFrame(data = output_3)\n\noutput_4 = {'PassengerId': test.PassengerId, 'Survived': y_vc_all}\nsubmission_3 = pd.DataFrame(data = output_4)\n\nfinal_data_comp = {'PassengerId': test.PassengerId, \n                   'Survived_vc_hard': y_vc_hard, \n                   'Survived_rf': y_rf, \n                   'Survived_vc_soft' : y_soft, \n                   'Survived_vc_all' : y_vc_all}\n\ncomparison = pd.DataFrame(data=final_data_comp)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:46:51.861311Z","iopub.execute_input":"2023-11-19T19:46:51.862030Z","iopub.status.idle":"2023-11-19T19:46:51.870270Z","shell.execute_reply.started":"2023-11-19T19:46:51.861997Z","shell.execute_reply":"2023-11-19T19:46:51.869538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Submitting the files\nsubmission.to_csv('submission_rf.csv', index =False)\nsubmission_1.to_csv('submission_vc_hard.csv',index=False)\nsubmission_2.to_csv('submission_vc_soft.csv', index=False)\nsubmission_3.to_csv('submission_vc_all.csv', index=False)\n\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:47:08.470120Z","iopub.execute_input":"2023-11-19T19:47:08.470979Z","iopub.status.idle":"2023-11-19T19:47:08.482301Z","shell.execute_reply.started":"2023-11-19T19:47:08.470945Z","shell.execute_reply":"2023-11-19T19:47:08.481293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}